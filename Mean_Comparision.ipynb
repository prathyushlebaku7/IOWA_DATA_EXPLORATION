{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total crashes is 6084 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/h3jt_tns2s14c8y5w9qptb6c0000gn/T/ipykernel_30909/1318962289.py:5: DtypeWarning: Columns (143,172,176,177,178,179,188,203,204,207,208,209,210,211,212,243,244,252,257,258,267,268,274,275,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/lebakuprathyushkumarreddy/Downloads/pavement_with_crashes_for_each_collisiontype_csvfile/merged_csv_file_using_geopandas.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "data = df[df[\"CRCOMNNR\"] == 1]\n",
    "# Grouping the data by 'OBJECTID' and counting the crashes\n",
    "crash_counts = data.groupby('OBJECTID').size()\n",
    "# Creating a new dataframe with OBJECTID and the crash counts\n",
    "pavement_section_data = data.drop_duplicates(subset='OBJECTID').set_index('OBJECTID')\n",
    "pavement_section_data['Crash_Count'] = crash_counts\n",
    "\n",
    "# Resetting the index to include OBJECTID as a column\n",
    "pavement_section_data.reset_index(inplace=True)\n",
    "\n",
    "# The final dataframe is stored in pavement_section_data\n",
    "\n",
    "pavement_section_data[\"Crash_Rate\"]= pavement_section_data[\"Crash_Count\"] *100000000/(pavement_section_data[\"AADT\"]*pavement_section_data[\"PMIS_LENGTH\"]*365)\n",
    "\n",
    "print(f\"Total crashes is {pavement_section_data['Crash_Count'].sum()} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean crash rates per million vmt:\n",
      " IRI_Category\n",
      "Good     56.355456\n",
      "Fair     72.519177\n",
      "Poor    119.595094\n",
      "Name: Crash_Rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "iri_bins = [0, 95, 170, float('inf')]\n",
    "iri_labels = ['Good', 'Fair', 'Poor']\n",
    "pavement_section_data['IRI_Category'] = pd.cut(pd.to_numeric(pavement_section_data['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n",
    "mean_crash_rates = pavement_section_data.groupby('IRI_Category')['Crash_Rate'].mean() # to find mean crash rate in each segment\n",
    "print(\"Mean crash rates per million vmt:\\n\", mean_crash_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "  Fair   Good -16.1637 0.0004 -26.0999 -6.2275   True\n",
      "  Fair   Poor  47.0759    0.0  28.2187 65.9331   True\n",
      "  Good   Poor  63.2396    0.0  44.8511 81.6281   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Assuming pavement_section_data is your DataFrame\n",
    "# Check and handle missing values\n",
    "pavement_section_data.dropna(subset=['Crash_Rate', 'IRI_Category'], inplace=True)\n",
    "\n",
    "# Convert IRI_Category to categorical if not already\n",
    "pavement_section_data['IRI_Category'] = pd.Categorical(pavement_section_data['IRI_Category'])\n",
    "\n",
    "# Perform the Tukey's test\n",
    "tukey_results = pairwise_tukeyhsd(endog=pavement_section_data['Crash_Rate'], \n",
    "                                  groups=pavement_section_data['IRI_Category'], \n",
    "                                  alpha=0.05)\n",
    "\n",
    "# Print summary\n",
    "print(tukey_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between 'Good' and 'Fair': LSD = 4.5488 (not significant), p-value = 0.0000\n",
      "Value of LSD: 4.548827948480511\n",
      "Value of Crirical LSD: 6.968307337928697\n",
      "Comparison between 'Good' and 'Poor': LSD = 2.5514 (not significant), p-value = 0.0108\n",
      "Value of LSD: 2.551442539311478\n",
      "Value of Crirical LSD: 12.423415649770298\n",
      "Comparison between 'Fair' and 'Poor': LSD = 2.4048 (not significant), p-value = 0.0163\n",
      "Value of LSD: 2.4047625373288244\n",
      "Value of Crirical LSD: 13.181189693507598\n"
     ]
    }
   ],
   "source": [
    "#Fishers LSD Test \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f, t\n",
    "\n",
    "# Perform ANOVA to test for overall group differences\n",
    "groups = [pavement_section_data[pavement_section_data['IRI_Category'] == label]['Crash_Rate'] for label in iri_labels]\n",
    "n_groups = len(groups)\n",
    "n_total = len(pavement_section_data['Crash_Rate'])\n",
    "n_obs = [len(group) for group in groups]\n",
    "mean_group = [group.mean() for group in groups]\n",
    "overall_mean = pavement_section_data['Crash_Rate'].mean()\n",
    "\n",
    "# Calculate the sum of squares between groups (SSB)\n",
    "SSB = sum([n * (mean - overall_mean)**2 for n, mean in zip(n_obs, mean_group)])\n",
    "\n",
    "# Calculate the mean square between groups (MSB)\n",
    "MSB = SSB / (n_groups - 1)\n",
    "\n",
    "# Calculate the mean square error (MSE)\n",
    "SSE = sum([(n - 1) * group.var() for n, group in zip(n_obs, groups)])\n",
    "MSE = SSE / (n_total - n_groups)\n",
    "\n",
    "# Calculate the F-statistic\n",
    "F = MSB / MSE\n",
    "\n",
    "# Calculate the critical value from the F-distribution\n",
    "alpha = 0.05\n",
    "df1 = n_groups - 1\n",
    "df2 = n_total - n_groups\n",
    "critical_value = f.ppf(1 - alpha, df1, df2)\n",
    "\n",
    "# Perform pairwise comparisons using Fisher's LSD and calculate p-values\n",
    "from itertools import combinations\n",
    "pairwise_comparisons = list(combinations(iri_labels, 2))\n",
    "for label1, label2 in pairwise_comparisons:\n",
    "    group1 = pavement_section_data[pavement_section_data['IRI_Category'] == label1]['Crash_Rate']\n",
    "    group2 = pavement_section_data[pavement_section_data['IRI_Category'] == label2]['Crash_Rate']\n",
    "    \n",
    "    # Calculate the pooled standard error\n",
    "    pooled_var = ((n_obs[0] - 1) * group1.var() + (n_obs[1] - 1) * group2.var()) / (n_obs[0] + n_obs[1] - 2)\n",
    "    pooled_se = np.sqrt(pooled_var * (1/n_obs[0] + 1/n_obs[1]))\n",
    "    \n",
    "    # Calculate the LSD\n",
    "    lsd = abs(mean_group[0] - mean_group[1]) / pooled_se\n",
    "    # Calculate the critical LSD value\n",
    "    critical_lsd = t.ppf(1 - alpha/2, df2) * pooled_se\n",
    "   \n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * (1 - t.cdf(abs(lsd), df2))\n",
    "    \n",
    "    if lsd > critical_lsd:\n",
    "        print(f\"Comparison between '{label1}' and '{label2}': LSD = {lsd:.4f} (significant), p-value = {p_value:.4f}\")\n",
    "        print(f\"Value of LSD: {lsd}\")\n",
    "        print(f\"Value of Crirical LSD: {critical_lsd}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Comparison between '{label1}' and '{label2}': LSD = {lsd:.4f} (not significant), p-value = {p_value:.4f}\")\n",
    "        print(f\"Value of LSD: {lsd}\")\n",
    "        print(f\"Value of Crirical LSD: {critical_lsd}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
