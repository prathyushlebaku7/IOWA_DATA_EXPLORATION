{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total crashes is 21536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/h3jt_tns2s14c8y5w9qptb6c0000gn/T/ipykernel_31714/1261433241.py:5: DtypeWarning: Columns (143,172,176,177,178,179,188,203,204,207,208,209,210,211,212,243,244,252,257,258,267,268,274,275,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/lebakuprathyushkumarreddy/Downloads/pavement_with_crashes_for_each_collisiontype_csvfile/merged_csv_file_using_geopandas.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "data = df\n",
    "# Grouping the data by 'OBJECTID' and counting the crashes\n",
    "crash_counts = data.groupby('OBJECTID').size()\n",
    "# Creating a new dataframe with OBJECTID and the crash counts\n",
    "pavement_section_data = data.drop_duplicates(subset='OBJECTID').set_index('OBJECTID')\n",
    "pavement_section_data['Crash_Count'] = crash_counts\n",
    "\n",
    "# Resetting the index to include OBJECTID as a column\n",
    "pavement_section_data.reset_index(inplace=True)\n",
    "\n",
    "# The final dataframe is stored in pavement_section_data\n",
    "\n",
    "pavement_section_data[\"Crash_Rate\"]= pavement_section_data[\"Crash_Count\"] *100000000/(pavement_section_data[\"AADT\"]*pavement_section_data[\"PMIS_LENGTH\"]*365)\n",
    "\n",
    "print(f\"Total crashes is {pavement_section_data['Crash_Count'].sum()} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean crash rates per million vmt:\n",
      " IRI_Category\n",
      "Good    134.123662\n",
      "Fair    225.617394\n",
      "Poor    468.304529\n",
      "Name: Crash_Rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "iri_bins = [0, 95, 170, float('inf')]\n",
    "iri_labels = ['Good', 'Fair', 'Poor']\n",
    "pavement_section_data['IRI_Category'] = pd.cut(pd.to_numeric(pavement_section_data['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n",
    "mean_crash_rates = pavement_section_data.groupby('IRI_Category')['Crash_Rate'].mean() # to find mean crash rate in each segment\n",
    "print(\"Mean crash rates per million vmt:\\n\", mean_crash_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Test: p-value = 3.304575171596344e-88\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      "group1 group2 meandiff p-adj   lower    upper   reject\n",
      "------------------------------------------------------\n",
      "  Fair   Good -91.4937   0.0 -114.4243 -68.5632   True\n",
      "  Fair   Poor 242.6871   0.0  203.1637 282.2106   True\n",
      "  Good   Poor 334.1809   0.0  295.5067 372.8551   True\n",
      "------------------------------------------------------\n",
      "\n",
      "Fisher's LSD Test Results:\n",
      "Good-Fair: t-statistic = -9.549862098734893, p-value = 3.57238159195401e-21\n",
      "Good-Poor: t-statistic = -13.912915260260002, p-value = 6.93844278612184e-35\n",
      "Fair-Poor: t-statistic = -9.689958845947373, p-value = 5.1556135759091546e-20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "iri_bins = [0, 95, 170, float('inf')]\n",
    "iri_labels = ['Good', 'Fair', 'Poor']\n",
    "pavement_section_data['IRI_Category'] = pd.cut(pd.to_numeric(pavement_section_data['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n",
    "\n",
    "# Extracting crash rates for each IRI category\n",
    "good_iri_crash_rates = pavement_section_data[pavement_section_data['IRI_Category'] == 'Good']['Crash_Rate'].dropna()\n",
    "fair_iri_crash_rates = pavement_section_data[pavement_section_data['IRI_Category'] == 'Fair']['Crash_Rate'].dropna()\n",
    "poor_iri_crash_rates = pavement_section_data[pavement_section_data['IRI_Category'] == 'Poor']['Crash_Rate'].dropna()\n",
    "\n",
    "# ANOVA Test\n",
    "anova_result = f_oneway(good_iri_crash_rates, fair_iri_crash_rates, poor_iri_crash_rates)\n",
    "print(f\"ANOVA Test: p-value = {anova_result.pvalue}\")\n",
    "\n",
    "# Proceed with post-hoc tests if ANOVA is significant\n",
    "if anova_result.pvalue < 0.05:\n",
    "    # Tukey-Kramer Test\n",
    "    crash_rates = np.concatenate([good_iri_crash_rates, fair_iri_crash_rates, poor_iri_crash_rates])\n",
    "    iri_categories = ['Good'] * len(good_iri_crash_rates) + ['Fair'] * len(fair_iri_crash_rates) + ['Poor'] * len(poor_iri_crash_rates)\n",
    "\n",
    "    tukey_result = pairwise_tukeyhsd(endog=crash_rates, groups=iri_categories, alpha=0.05)\n",
    "    print(tukey_result.summary())\n",
    "    \n",
    "    print()\n",
    "    # Fisher's LSD Test\n",
    "    fisher_lsd_results = {\n",
    "        'Good-Fair': stats.ttest_ind(good_iri_crash_rates, fair_iri_crash_rates, equal_var=False),\n",
    "        'Good-Poor': stats.ttest_ind(good_iri_crash_rates, poor_iri_crash_rates, equal_var=False),\n",
    "        'Fair-Poor': stats.ttest_ind(fair_iri_crash_rates, poor_iri_crash_rates, equal_var=False)\n",
    "    }\n",
    "\n",
    "    print(\"Fisher's LSD Test Results:\")\n",
    "    for comparison, result in fisher_lsd_results.items():\n",
    "        print(f\"{comparison}: t-statistic = {result.statistic}, p-value = {result.pvalue}\")\n",
    "else:\n",
    "    print(\"No significant differences found in ANOVA, post-hoc tests not required.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
